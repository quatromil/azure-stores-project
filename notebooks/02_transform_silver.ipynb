{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Leer Data Delta Bronze"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "execution_finish_time": "2025-10-25T00:43:15.8580322Z",
              "execution_start_time": "2025-10-25T00:42:58.8009678Z",
              "livy_statement_state": "available",
              "normalized_state": "finished",
              "parent_msg_id": "26a93fb2-c037-4020-be8c-ce51ef5fbd83",
              "queued_time": "2025-10-25T00:42:58.713683Z",
              "session_id": "60",
              "session_start_time": null,
              "spark_jobs": null,
              "spark_pool": "sparkpoolnew",
              "state": "finished",
              "statement_id": 4,
              "statement_ids": [
                4
              ]
            },
            "text/plain": [
              "StatementMeta(sparkpoolnew, 60, 4, Finished, Available, Finished)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from pyspark.sql.functions import col\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "# Variables\n",
        "container_name = \"datalake\"\n",
        "root_silver_folder = \"silver\"\n",
        "root_processed_folder = \"processed\"\n",
        "\n",
        "show_debug = False\n",
        "\n",
        "# Crear sesi√≥n Spark\n",
        "spark = SparkSession.builder.appName(\"ReadDeltaData\").getOrCreate()\n",
        "\n",
        "# Rutas del Contenedor en ADLS Gen2\n",
        "sales_delta_path = f\"abfss://{container_name}@adlsstoresproject.dfs.core.windows.net/{root_processed_folder}/sales/\"\n",
        "customers_delta_path = f\"abfss://{container_name}@adlsstoresproject.dfs.core.windows.net/{root_processed_folder}/customers/\"\n",
        "products_delta_path = f\"abfss://{container_name}@adlsstoresproject.dfs.core.windows.net/{root_processed_folder}/products/\"\n",
        "suppliers_delta_path = f\"abfss://{container_name}@adlsstoresproject.dfs.core.windows.net/{root_processed_folder}/suppliers/\"\n",
        "\n",
        "# Leer los archivos Delta\n",
        "df_products = spark.read.format(\"delta\").load(products_delta_path)\n",
        "df_suppliers = spark.read.format(\"delta\").load(suppliers_delta_path)\n",
        "\n",
        "# Estos se deben leer filtrados para √∫nicamente obtener los registros que no se han validado\n",
        "df_sales = (\n",
        "    spark.read.format(\"delta\")\n",
        "    .load(sales_delta_path)\n",
        "    .where((col(\"is_validated\") == False) | (col(\"is_validated\") == 0))\n",
        ")\n",
        "\n",
        "df_customers = (\n",
        "    spark.read.format(\"delta\")\n",
        "    .load(customers_delta_path)\n",
        "    .where((col(\"is_validated\") == False) | (col(\"is_validated\") == 0))\n",
        ")\n",
        "\n",
        "# Mostrar los primeros registros\n",
        "if (show_debug == True):\n",
        "    print(\"Sales:\")\n",
        "    df_sales.show(3)\n",
        "\n",
        "    print(\"Customers:\")\n",
        "    df_customers.show(3)\n",
        "\n",
        "    print(\"Products:\")\n",
        "    df_products.show(3)\n",
        "\n",
        "    print(\"Suppliers:\")\n",
        "    df_suppliers.show(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Limpieza - Transformaci√≥n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "execution_finish_time": "2025-10-25T00:43:16.0729565Z",
              "execution_start_time": "2025-10-25T00:43:15.8689862Z",
              "livy_statement_state": "available",
              "normalized_state": "finished",
              "parent_msg_id": "7633c887-c7b1-4578-9466-2a41123be54d",
              "queued_time": "2025-10-25T00:42:58.7616992Z",
              "session_id": "60",
              "session_start_time": null,
              "spark_jobs": null,
              "spark_pool": "sparkpoolnew",
              "state": "finished",
              "statement_id": 5,
              "statement_ids": [
                5
              ]
            },
            "text/plain": [
              "StatementMeta(sparkpoolnew, 60, 5, Finished, Available, Finished)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from pyspark.sql.functions import col, when, trim, lower, lit, length, regexp_replace, regexp_extract, to_timestamp\n",
        "from pyspark.sql.types import IntegerType, DoubleType, StringType, TimestampType"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "execution_finish_time": "2025-10-25T00:43:16.3087844Z",
              "execution_start_time": "2025-10-25T00:43:16.0841013Z",
              "livy_statement_state": "available",
              "normalized_state": "finished",
              "parent_msg_id": "e429e5b8-03b2-46e3-8fbf-bc03108ea31b",
              "queued_time": "2025-10-25T00:42:58.9505316Z",
              "session_id": "60",
              "session_start_time": null,
              "spark_jobs": null,
              "spark_pool": "sparkpoolnew",
              "state": "finished",
              "statement_id": 6,
              "statement_ids": [
                6
              ]
            },
            "text/plain": [
              "StatementMeta(sparkpoolnew, 60, 6, Finished, Available, Finished)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#===============\n",
        "def remove_null_or_empty(df, column_name):\n",
        "    \"\"\"\n",
        "    Elimina los registros donde una columna tenga valores nulos o vac√≠os.\n",
        "    Retorna el DataFrame limpio y muestra cu√°ntos registros fueron eliminados.\n",
        "    \"\"\"\n",
        "    invalid_count = df.filter(col(column_name).isNull() | (col(column_name) == \"\")).count()\n",
        "\n",
        "    if invalid_count > 0:\n",
        "        print(f\"Se eliminaron {invalid_count} registros con {column_name} vac√≠o o nulo.\")\n",
        "        df = df.filter(col(column_name).isNotNull() & (col(column_name) != \"\"))\n",
        "    else:\n",
        "        print(f\"No se encontraron registros vac√≠os o nulos en {column_name}.\")\n",
        "\n",
        "    return df\n",
        "\n",
        "#===============\n",
        "def is_numeric_int(df, column_name):\n",
        "    \"\"\"\n",
        "    Verifica si una columna tiene valores no num√©ricos.\n",
        "    Retorna True si se encontraron valores enteros inv√°lidos, False si todo est√° bien.\n",
        "    \"\"\"\n",
        "    invalid_count = df.filter(~col(column_name).rlike(\"^[0-9]+$\")).count()\n",
        "    return invalid_count > 0\n",
        "\n",
        "#===============\n",
        "def is_numeric_double(df, column_name):\n",
        "    \"\"\"\n",
        "    Verifica si una columna tiene valores no num√©ricos.\n",
        "    Retorna True si se encontraron valores decimales inv√°lidos, False si todo est√° bien.\n",
        "    \"\"\"\n",
        "    invalid_count = df.filter(~col(column_name).rlike(\"^[0-9]+(\\\\.[0-9]+)?$\")).count()\n",
        "    return invalid_count > 0\n",
        "\n",
        "#===============\n",
        "def greater_than_zero(df, column_name):\n",
        "    \"\"\"\n",
        "    Verifica si una columna contiene valores menores o iguales a 0.\n",
        "    Retorna True si hay valores no positivos, False si todo est√° bien.\n",
        "    \"\"\"\n",
        "    invalid_count = df.filter(col(column_name).cast(\"double\") <= 0).count()\n",
        "    return invalid_count > 0\n",
        "\n",
        "#===============\n",
        "def clean_name(df, column_name):\n",
        "    \"\"\"\n",
        "    Elimina caracteres especiales del campo firstname,\n",
        "    pero mantiene letras (incluyendo √± y tildes), espacios, puntos y ap√≥strofes.\n",
        "    Retorna el DataFrame con la columna limpia.\n",
        "    \"\"\"\n",
        "    # Permite letras con tildes, √±/√ë, espacios, puntos y ap√≥strofes\n",
        "    df = df.withColumn(\n",
        "        column_name,\n",
        "        regexp_replace(\n",
        "            col(column_name),\n",
        "            r\"[^a-zA-Z√°√©√≠√≥√∫√Å√â√ç√ì√ö√±√ë√º√ú' .]\",  # mantiene caracteres v√°lidos\n",
        "            \"\"\n",
        "        )\n",
        "    )\n",
        "    print(f\"Caracteres especiales eliminados en la columna '{column_name}'.\")\n",
        "    return df\n",
        "\n",
        "#===============\n",
        "def clean_email(df, column_name, default_value=\"no-email@domain.com\", invalid_emails=None):\n",
        "    \"\"\"\n",
        "    Limpia y valida direcciones de correo electr√≥nico.\n",
        "    \n",
        "    - Reemplaza valores nulos, vac√≠os, inv√°lidos o de una lista de correos no v√°lidos.\n",
        "    - El valor est√°ndar se pasa como par√°metro (default: 'no-email@domain.com').\n",
        "    - Puedes pasar una lista de correos inv√°lidos comunes en el par√°metro `invalid_emails`.\n",
        "\n",
        "    Retorna el DataFrame con el campo limpio.\n",
        "    \"\"\"\n",
        "    # Si no se pasan correos inv√°lidos personalizados, usar algunos por defecto\n",
        "    if invalid_emails is None:\n",
        "        invalid_emails = [\n",
        "            \"notengo@hotmail.com\",\n",
        "            \"sincorreo@gmail.com\",\n",
        "            \"noaplica@hotmail.com\",\n",
        "            \"noaplica@gmail.com\",\n",
        "            \"ninguno@gmail.com\",\n",
        "            \"ninguno@hotmail.com\",\n",
        "            \"no.tengo@gmail.com\",\n",
        "            \"sinemail@gmail.com\"\n",
        "        ]\n",
        "\n",
        "    # Convertimos la lista a min√∫sculas para hacer comparaciones insensibles a may√∫sculas\n",
        "    invalid_emails = [e.lower() for e in invalid_emails]\n",
        "\n",
        "    # Expresi√≥n regular est√°ndar para validar correos electr√≥nicos\n",
        "    email_regex = r\"^[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Za-z]{2,}$\"\n",
        "\n",
        "    # Limpieza y validaci√≥n\n",
        "    df = df.withColumn(\n",
        "        column_name,\n",
        "        when(\n",
        "            # Condici√≥n de correo v√°lido\n",
        "            col(column_name).isNotNull() &\n",
        "            (trim(col(column_name)) != \"\") &\n",
        "            col(column_name).rlike(email_regex) &\n",
        "            (~lower(col(column_name)).isin(invalid_emails)),\n",
        "            col(column_name)\n",
        "        ).otherwise(lit(default_value))\n",
        "    )\n",
        "\n",
        "    print(f\"Correos inv√°lidos o gen√©ricos en '{column_name}' reemplazados por '{default_value}'.\")\n",
        "    return df\n",
        "\n",
        "#===============\n",
        "def clean_phone_number(df, column_name, default_value=\"0000000000\", country_prefix=None):\n",
        "    \"\"\"\n",
        "    Estandariza n√∫meros de celular:\n",
        "      - Elimina caracteres no num√©ricos (espacios, guiones, par√©ntesis, +, etc.)\n",
        "      - Opcionalmente agrega un prefijo de pa√≠s si se define (por ejemplo, '57' para Colombia)\n",
        "      - Reemplaza valores vac√≠os o inv√°lidos con un valor est√°ndar\n",
        "\n",
        "    Par√°metros:\n",
        "        df (DataFrame): DataFrame de entrada\n",
        "        column_name (str): Nombre de la columna de celular\n",
        "        default_value (str): Valor a usar si el n√∫mero es inv√°lido o vac√≠o\n",
        "        country_prefix (str): Prefijo de pa√≠s opcional (por ejemplo, \"57\")\n",
        "\n",
        "    Retorna:\n",
        "        DataFrame con el n√∫mero estandarizado\n",
        "    \"\"\"\n",
        "\n",
        "    # Quitar todos los caracteres que no sean d√≠gitos\n",
        "    df = df.withColumn(\n",
        "        column_name,\n",
        "        regexp_replace(trim(col(column_name)), r\"[^0-9]\", \"\")\n",
        "    )\n",
        "\n",
        "    # Agregar prefijo de pa√≠s si aplica y no est√° vac√≠o\n",
        "    if country_prefix:\n",
        "        df = df.withColumn(\n",
        "            column_name,\n",
        "            when(\n",
        "                (col(column_name).isNotNull()) & (col(column_name) != \"\") & (~col(column_name).startswith(country_prefix)),\n",
        "                lit(country_prefix) + col(column_name)\n",
        "            ).otherwise(col(column_name))\n",
        "        )\n",
        "\n",
        "    # Reemplazar vac√≠os, nulos o demasiado cortos con el valor por defecto\n",
        "    df = df.withColumn(\n",
        "        column_name,\n",
        "        when(\n",
        "            (col(column_name).isNull()) | \n",
        "            (trim(col(column_name)) == \"\") | \n",
        "            (length(col(column_name)) < 8) | \n",
        "            (length(col(column_name)) > 12),\n",
        "            lit(default_value)\n",
        "        ).otherwise(col(column_name))\n",
        "    )\n",
        "\n",
        "    print(f\"N√∫meros de celular en '{column_name}' estandarizados correctamente.\")\n",
        "    return df\n",
        "\n",
        "#==============="
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "### df_sales"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "execution_finish_time": "2025-10-25T00:43:42.5392981Z",
              "execution_start_time": "2025-10-25T00:43:16.3203841Z",
              "livy_statement_state": "available",
              "normalized_state": "finished",
              "parent_msg_id": "73ee7cd0-ab9b-4d68-9105-e273b98fe243",
              "queued_time": "2025-10-25T00:42:59.2212396Z",
              "session_id": "60",
              "session_start_time": null,
              "spark_jobs": null,
              "spark_pool": "sparkpoolnew",
              "state": "finished",
              "statement_id": 7,
              "statement_ids": [
                7
              ]
            },
            "text/plain": [
              "StatementMeta(sparkpoolnew, 60, 7, Finished, Available, Finished)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "No se encontraron registros vac√≠os o nulos en sale_id.\n",
            "No se encontraron registros vac√≠os o nulos en customer_id.\n",
            "No se encontraron registros vac√≠os o nulos en product_id.\n",
            "No se encontraron registros vac√≠os o nulos en store.\n",
            "Ejecuci√≥n Ok\n"
          ]
        }
      ],
      "source": [
        "# --------------------------\n",
        "df_sales_alert = False\n",
        "\n",
        "# --------------------------\n",
        "# AGREGAR CAMPO DE INGESTA INCREMENTAL\n",
        "df_sales = df_sales.withColumn(\n",
        "    \"is_validated\",\n",
        "    lit(False)\n",
        ")\n",
        "\n",
        "# --------------------------\n",
        "# QUITAR REGISTROS VACIOS/NULOS\n",
        "df_sales = remove_null_or_empty(df_sales, \"sale_id\")\n",
        "df_sales = remove_null_or_empty(df_sales, \"customer_id\")\n",
        "df_sales = remove_null_or_empty(df_sales, \"product_id\")\n",
        "df_sales = remove_null_or_empty(df_sales, \"store\")\n",
        "\n",
        "# --------------------------\n",
        "# REEMPLAZAR FECHAS INVALIDAS POR FECHA ESTANDAR\n",
        "df_sales = df_sales.withColumn(\n",
        "    \"created_at\",\n",
        "    when(\n",
        "        # Se reemplaza por Datetime est√°ndar cuando no tiene el formato correcto, est√° nulo o vac√≠o\n",
        "        col(\"created_at\").rlike(\"^[0-9]{4}-[0-9]{2}-[0-9]{2} [0-9]{2}:[0-9]{2}:[0-9]{2}$\") &\n",
        "        col(\"created_at\").isNotNull() &\n",
        "        (trim(col(\"created_at\")) != \"\"),\n",
        "        col(\"created_at\")\n",
        "    ).otherwise(\"1900-01-01 00:00:00\")\n",
        ")\n",
        "\n",
        "# --------------------------\n",
        "# VALIDAR CAMPOS\n",
        "# Que solo tenga valores num√©ricos enteros\n",
        "if (is_numeric_int(df_sales, \"sale_id\") | is_numeric_int(df_sales, \"product_id\") | is_numeric_int(df_sales, \"customer_id\") | is_numeric_int(df_sales, \"quantity\")):\n",
        "    df_sales_alert = True\n",
        "    print(\"Que solo tenga valores num√©ricos enteros\")\n",
        "\n",
        "# Que solo tenga valores num√©ricos decimales\n",
        "if (is_numeric_double(df_sales, \"unit_price\") | is_numeric_double(df_sales, \"total_amount\")):    \n",
        "    df_sales_alert = True\n",
        "    print(\"Que solo tenga valores num√©ricos decimales\")\n",
        "\n",
        "# ==================\n",
        "if (df_sales_alert):\n",
        "    raise Exception(\"üö´ Ejecuci√≥n detenida: Se encontraron valores inv√°lidos en la columnas.\")\n",
        "else:\n",
        "    print(\"Ejecuci√≥n Ok\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "execution_finish_time": "2025-10-25T00:43:46.4700382Z",
              "execution_start_time": "2025-10-25T00:43:42.5504078Z",
              "livy_statement_state": "available",
              "normalized_state": "finished",
              "parent_msg_id": "8bdba944-77ee-4edb-ae92-70f481f60cb6",
              "queued_time": "2025-10-25T00:42:59.3016011Z",
              "session_id": "60",
              "session_start_time": null,
              "spark_jobs": null,
              "spark_pool": "sparkpoolnew",
              "state": "finished",
              "statement_id": 8,
              "statement_ids": [
                8
              ]
            },
            "text/plain": [
              "StatementMeta(sparkpoolnew, 60, 8, Finished, Available, Finished)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Definir Schema sales\n",
        "df_sales_clean = df_sales.select(\n",
        "    col(\"sale_id\").cast(IntegerType()).alias(\"sale_id\"),\n",
        "    col(\"product_id\").cast(IntegerType()).alias(\"product_id\"), \n",
        "    col(\"customer_id\").cast(IntegerType()).alias(\"customer_id\"),\n",
        "    col(\"quantity\").cast(StringType()).alias(\"quantity\"),\n",
        "    regexp_replace(col(\"unit_price\"), \",\", \".\").cast(DoubleType()).alias(\"unit_price\"),\n",
        "    regexp_replace(col(\"total_amount\"), \",\", \".\").cast(DoubleType()).alias(\"total_amount\"),\n",
        "    col(\"sale_date\").cast(StringType()).alias(\"sale_date\"),\n",
        "    col(\"sale_time\").cast(StringType()).alias(\"sale_time\"),\n",
        "    col(\"store\").cast(StringType()).alias(\"store\"),\n",
        "    to_timestamp(col(\"created_at\"), \"yyyy-MM-dd HH:mm:ss\").alias(\"created_at\"),\n",
        "    col(\"year\").cast(StringType()).alias(\"year\"),\n",
        "    col(\"month\").cast(StringType()).alias(\"month\"),\n",
        "    col(\"day\").cast(StringType()).alias(\"day\"),\n",
        "    col(\"unique_id\").cast(StringType()).alias(\"unique_id\"),\n",
        "    lit(False).alias(\"is_validated\")\n",
        ")\n",
        "\n",
        "# Que tenga valores positivos\n",
        "if (greater_than_zero(df_sales_clean, \"sale_id\")):\n",
        "    df_sales_alert = True\n",
        "    print(\"Que sale_id tenga valores positivos\")\n",
        "\n",
        "if (greater_than_zero(df_sales_clean, \"product_id\")):\n",
        "    df_sales_alert = True\n",
        "    print(\"Que product_id tenga valores positivos\")\n",
        "\n",
        "if (greater_than_zero(df_sales_clean, \"customer_id\")):\n",
        "    df_sales_alert = True\n",
        "    print(\"Que customer_id tenga valores positivos\")\n",
        "\n",
        "# Mostrar esquema y datos\n",
        "if (show_debug  == True):\n",
        "    df_sales_clean.printSchema()\n",
        "    df_sales_clean.show(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "### df_customers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "execution_finish_time": "2025-10-25T00:43:51.781085Z",
              "execution_start_time": "2025-10-25T00:43:46.4797831Z",
              "livy_statement_state": "available",
              "normalized_state": "finished",
              "parent_msg_id": "d1ed2cfc-5481-4dbb-9580-a92280ba3ee8",
              "queued_time": "2025-10-25T00:42:59.377625Z",
              "session_id": "60",
              "session_start_time": null,
              "spark_jobs": null,
              "spark_pool": "sparkpoolnew",
              "state": "finished",
              "statement_id": 9,
              "statement_ids": [
                9
              ]
            },
            "text/plain": [
              "StatementMeta(sparkpoolnew, 60, 9, Finished, Available, Finished)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "No se encontraron registros vac√≠os o nulos en customer_id.\n",
            "No se encontraron registros vac√≠os o nulos en store.\n",
            "Caracteres especiales eliminados en la columna 'firstname'.\n",
            "Caracteres especiales eliminados en la columna 'lastname'.\n",
            "Correos inv√°lidos o gen√©ricos en 'email' reemplazados por 'no-email@domain.com'.\n",
            "N√∫meros de celular en 'phone' estandarizados correctamente.\n",
            "Ejecuci√≥n Ok\n"
          ]
        }
      ],
      "source": [
        "# --------------------------\n",
        "df_customers_alert = False\n",
        "\n",
        "# --------------------------\n",
        "# AGREGAR CAMPO DE INGESTA INCREMENTAL\n",
        "df_customers = df_customers.withColumn(\n",
        "    \"is_validated\",\n",
        "    lit(False)\n",
        ")\n",
        "\n",
        "# --------------------------\n",
        "# QUITAR REGISTROS VACIOS/NULOS\n",
        "df_customers = remove_null_or_empty(df_customers, \"customer_id\")\n",
        "df_customers = remove_null_or_empty(df_customers, \"store\")\n",
        "\n",
        "# --------------------------\n",
        "# REEMPLAZAR FECHAS INVaLIDAS POR FECHA ESTANDAR\n",
        "df_customers = df_customers.withColumn(\n",
        "    \"created_at\",\n",
        "    when(\n",
        "        # Se reemplaza por Datetime est√°ndar cuando no tiene el formato correcto, est√° nulo o vac√≠o\n",
        "        col(\"created_at\").rlike(\"^[0-9]{4}-[0-9]{2}-[0-9]{2} [0-9]{2}:[0-9]{2}:[0-9]{2}$\") &\n",
        "        col(\"created_at\").isNotNull() &\n",
        "        (trim(col(\"created_at\")) != \"\"),\n",
        "        col(\"created_at\")\n",
        "    ).otherwise(\"1900-01-01 00:00:00\")\n",
        ")\n",
        "\n",
        "# --------------------------\n",
        "# VALIDAR CAMPOS\n",
        "# Que solo tenga valores num√©ricos enteros\n",
        "if (is_numeric_int(df_sales, \"customer_id\")):\n",
        "    df_customers_alert = True\n",
        "    print(\"Que solo tenga valores num√©ricos enteros\")\n",
        "\n",
        "# --------------------------\n",
        "# LIMPIAR NOMBRES Y APELLIDOS\n",
        "df_customers = clean_name(df_customers, \"firstname\")\n",
        "df_customers = clean_name(df_customers, \"lastname\")\n",
        "\n",
        "# --------------------------\n",
        "# LIMPIAR CORREOS\n",
        "df_customers = clean_email(df_customers, \"email\")\n",
        "\n",
        "# --------------------------\n",
        "# LIMPIAR CELULARES\n",
        "df_customers = clean_phone_number(df_customers, \"phone\")\n",
        "\n",
        "# ==================\n",
        "if (df_customers_alert):\n",
        "    raise Exception(\"üö´ Ejecuci√≥n detenida: Se encontraron valores inv√°lidos en la columnas.\")\n",
        "else:\n",
        "    print(\"Ejecuci√≥n Ok\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "execution_finish_time": "2025-10-25T00:43:52.9258675Z",
              "execution_start_time": "2025-10-25T00:43:51.8168472Z",
              "livy_statement_state": "available",
              "normalized_state": "finished",
              "parent_msg_id": "d4270875-fbca-4caf-8b88-d13371da5f02",
              "queued_time": "2025-10-25T00:42:59.4386344Z",
              "session_id": "60",
              "session_start_time": null,
              "spark_jobs": null,
              "spark_pool": "sparkpoolnew",
              "state": "finished",
              "statement_id": 10,
              "statement_ids": [
                10
              ]
            },
            "text/plain": [
              "StatementMeta(sparkpoolnew, 60, 10, Finished, Available, Finished)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Definir Schema customers\n",
        "df_customers_clean = df_customers.select(\n",
        "    col(\"customer_id\").cast(IntegerType()).alias(\"customer_id\"),\n",
        "    col(\"firstname\").cast(StringType()).alias(\"firstname\"),\n",
        "    col(\"lastname\").cast(StringType()).alias(\"lastname\"),\n",
        "    col(\"email\").cast(StringType()).alias(\"email\"),\n",
        "    col(\"phone\").cast(StringType()).alias(\"phone\"),\n",
        "    col(\"store\").cast(StringType()).alias(\"store\"),\n",
        "    to_timestamp(col(\"created_at\"), \"yyyy-MM-dd HH:mm:ss\").alias(\"created_at\"),\n",
        "    col(\"year\").cast(StringType()).alias(\"year\"),\n",
        "    col(\"month\").cast(StringType()).alias(\"month\"),\n",
        "    col(\"day\").cast(StringType()).alias(\"day\"),\n",
        "    col(\"unique_id\").cast(StringType()).alias(\"unique_id\"),\n",
        "    lit(False).alias(\"is_validated\")\n",
        ")\n",
        "\n",
        "# Que tenga valores positivos\n",
        "if (greater_than_zero(df_sales_clean, \"customer_id\")):\n",
        "    df_customers_alert = True\n",
        "    print(\"Que customer_id tenga valores positivos\")\n",
        "\n",
        "# Mostrar esquema y datos\n",
        "if (show_debug  == True):\n",
        "    df_customers_clean.printSchema()\n",
        "    df_customers_clean.show(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Guardar en capa **Silver**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "execution_finish_time": "2025-10-25T00:44:05.5173574Z",
              "execution_start_time": "2025-10-25T00:43:52.9363997Z",
              "livy_statement_state": "available",
              "normalized_state": "finished",
              "parent_msg_id": "2f859923-d0bc-4507-b049-12d8cbe75d91",
              "queued_time": "2025-10-25T00:42:59.5173604Z",
              "session_id": "60",
              "session_start_time": null,
              "spark_jobs": null,
              "spark_pool": "sparkpoolnew",
              "state": "finished",
              "statement_id": 11,
              "statement_ids": [
                11
              ]
            },
            "text/plain": [
              "StatementMeta(sparkpoolnew, 60, 11, Finished, Available, Finished)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from delta.tables import DeltaTable\n",
        "\n",
        "silver_sales_path = \"abfss://datalake@adlsstoresproject.dfs.core.windows.net/silver/sales\"\n",
        "silver_customers_path = \"abfss://datalake@adlsstoresproject.dfs.core.windows.net/silver/customers\"\n",
        "\n",
        "# ===== MERGE SALES SILVER =====\n",
        "if DeltaTable.isDeltaTable(spark, silver_sales_path):\n",
        "    delta_sales = DeltaTable.forPath(spark, silver_sales_path)\n",
        "    \n",
        "    delta_sales.alias(\"target\").merge(\n",
        "        df_sales_clean.alias(\"source\"),\n",
        "        \"target.unique_id = source.unique_id\"\n",
        "    ).whenMatchedUpdateAll() \\\n",
        "     .whenNotMatchedInsertAll() \\\n",
        "     .execute()\n",
        "else:\n",
        "    # Si no existe, lo crea la primera vez\n",
        "    df_sales_clean.write.format(\"delta\") \\\n",
        "        .mode(\"overwrite\") \\\n",
        "        .partitionBy(\"year\", \"month\", \"day\") \\\n",
        "        .save(silver_sales_path)\n",
        "\n",
        "# ===== MERGE CUSTOMERS SILVER =====\n",
        "if DeltaTable.isDeltaTable(spark, silver_customers_path):\n",
        "    delta_customers = DeltaTable.forPath(spark, silver_customers_path)\n",
        "    \n",
        "    delta_customers.alias(\"target\").merge(\n",
        "        df_customers_clean.alias(\"source\"),\n",
        "        \"target.unique_id = source.unique_id\"\n",
        "    ).whenMatchedUpdateAll() \\\n",
        "     .whenNotMatchedInsertAll() \\\n",
        "     .execute()\n",
        "else:\n",
        "    df_customers_clean.write.format(\"delta\") \\\n",
        "        .mode(\"overwrite\") \\\n",
        "        .partitionBy(\"year\", \"month\", \"day\") \\\n",
        "        .save(silver_customers_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Actualizar estado de registros validados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "execution_finish_time": null,
              "execution_start_time": "2025-10-25T00:44:05.5296812Z",
              "livy_statement_state": "running",
              "normalized_state": "running",
              "parent_msg_id": "be0fc618-8814-401d-bbe9-7161102f58ae",
              "queued_time": "2025-10-25T00:42:59.5767544Z",
              "session_id": "60",
              "session_start_time": null,
              "spark_jobs": null,
              "spark_pool": "sparkpoolnew",
              "state": "submitted",
              "statement_id": 12,
              "statement_ids": [
                12
              ]
            },
            "text/plain": [
              "StatementMeta(sparkpoolnew, 60, 12, Submitted, Running, Running)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# ===== IS_VALIDATED SALES -> TRUE =====\n",
        "delta_bronze_sales = DeltaTable.forPath(spark, sales_delta_path)\n",
        "delta_bronze_sales.alias(\"bronze\").merge(\n",
        "    df_sales.select(\"unique_id\").alias(\"source\"),\n",
        "    \"bronze.unique_id = source.unique_id\"\n",
        ").whenMatchedUpdate(\n",
        "    set={\"is_validated\": lit(1)}\n",
        ").execute()\n",
        "print(\"‚úÖ is_validated marcado a 1 en sales.Bronze para registros procesados.\")\n",
        "\n",
        "# ===== IS_VALIDATED CUSTOMERS -> TRUE =====\n",
        "# Actualizar is_validated = 1 en Bronze para los unique_id procesados\n",
        "delta_bronze_customers = DeltaTable.forPath(spark, customers_delta_path)\n",
        "delta_bronze_customers.alias(\"bronze\").merge(\n",
        "    df_sales.select(\"unique_id\").alias(\"source\"),\n",
        "    \"bronze.unique_id = source.unique_id\"\n",
        ").whenMatchedUpdate(\n",
        "    set={\"is_validated\": lit(1)}\n",
        ").execute()\n",
        "print(\"‚úÖ is_validated marcado a 1 en customers.Bronze para registros procesados.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Crear **silver_db**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "execution_finish_time": null,
              "execution_start_time": null,
              "livy_statement_state": null,
              "normalized_state": "waiting",
              "parent_msg_id": "2bc88cc2-da1d-45b4-b555-00c988aa21f1",
              "queued_time": "2025-10-25T00:42:59.6849739Z",
              "session_id": null,
              "session_start_time": null,
              "spark_jobs": null,
              "spark_pool": null,
              "state": "waiting",
              "statement_id": -1,
              "statement_ids": null
            },
            "text/plain": [
              "StatementMeta(, , -1, Waiting, , Waiting)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Eliminar tablas:\n",
        "#spark.sql(\"DROP TABLE IF EXISTS silver_db.customers\")\n",
        "#spark.sql(\"DROP TABLE IF EXISTS silver_db.sales\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "execution_finish_time": null,
              "execution_start_time": null,
              "livy_statement_state": null,
              "normalized_state": "waiting",
              "parent_msg_id": "3caf7f5c-51d1-47bb-8a52-0d4bb8b75fc2",
              "queued_time": "2025-10-25T00:42:59.7671073Z",
              "session_id": null,
              "session_start_time": null,
              "spark_jobs": null,
              "spark_pool": null,
              "state": "waiting",
              "statement_id": -1,
              "statement_ids": null
            },
            "text/plain": [
              "StatementMeta(, , -1, Waiting, , Waiting)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "spark.sql(\"\"\"\n",
        "    CREATE DATABASE IF NOT EXISTS silver_db\n",
        "    LOCATION 'abfss://datalake@adlsstoresproject.dfs.core.windows.net/silver'\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "execution_finish_time": null,
              "execution_start_time": null,
              "livy_statement_state": null,
              "normalized_state": "waiting",
              "parent_msg_id": "5d5c2a69-f31b-493d-8a1e-484d127a3faa",
              "queued_time": "2025-10-25T00:42:59.8380547Z",
              "session_id": null,
              "session_start_time": null,
              "spark_jobs": null,
              "spark_pool": null,
              "state": "waiting",
              "statement_id": -1,
              "statement_ids": null
            },
            "text/plain": [
              "StatementMeta(, , -1, Waiting, , Waiting)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Registrar tabla de ventas\n",
        "spark.sql(f\"\"\"\n",
        "    CREATE TABLE IF NOT EXISTS silver_db.sales\n",
        "    USING DELTA\n",
        "    LOCATION '{silver_sales_path}'\n",
        "\"\"\")\n",
        "\n",
        "# Registrar tabla de clientes\n",
        "spark.sql(f\"\"\"\n",
        "    CREATE TABLE IF NOT EXISTS silver_db.customers\n",
        "    USING DELTA\n",
        "    LOCATION '{silver_customers_path}'\n",
        "\"\"\")"
      ]
    }
  ],
  "metadata": {
    "description": null,
    "kernelspec": {
      "display_name": "python",
      "name": "synapse_pyspark"
    },
    "language_info": {
      "name": "python"
    },
    "save_output": true,
    "synapse_widget": {
      "state": {},
      "version": "0.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
